#!/bin/bash
#PBS -N Spark_DEFOE_TotalDocuments
#PBS -l walltime=00:60:00
#PBS -l select=3:ncpus=36
#PBS -l place=scatter:excl
#PBS -A sc048
 
module load spack/cirrus
module load jdk-8u92-linux-x64-gcc-6.2.0-24xtmiy
module load anaconda/python3
source activate cirrus-py36

export SPARK_HOME=$HOME/spark-2.4.0-bin-hadoop2.7
export SPARK_MASTER_HOST=$HOSTNAME
export SPARK_MASTER_PORT=7077
export SPARK_MASTER_WEBUI_PORT=8080
export PATH=$SPARK_HOME/sbin:$SPARK_HOME/bin:$PATH

export NUM_NODES=3

cd $HOME/bash_scripts
rm -f master.log
rm -f driver.log
rm -f worker.log
rm -f slaves.log

nodes=($( cat $PBS_NODEFILE | sort | uniq ))
nnodes=${#nodes[@]}
last=$(( $nnodes - 1 ))

echo "`hostname`" > master.log
for each in "${nodes[@]}"
do
  echo "Nodo: $each"
done
 
# start resource manager only once
./start_master.sh
mastername=$(cat "master.log") 
echo "Started master on" $mastername


# getting the driver node - only one
flag=0
for each in "${nodes[@]}"
do
  each_node=${each%%.*}
  echo "the node to evaluate is $each_node comparing with $masternode"
  if [ $each_node != $mastername ] ; then
     echo "My driver will be $each_node"
     echo $each_node > driver.log
     flag=1
  fi
  if [ $flag == 1 ]; then
     echo "leaving the loop"
     break
  fi
done

drivername=$(cat "driver.log")

# start workers in all the nodes except the one where the master and driver were started
for i in "${nodes[@]}"

do
    echo $i
    ssh $i "cd $HOME/bash_scripts; ./start_worker.sh $mastername $drivername" &
done


sleep 30s

ssh $drivername "./spark-nls-keywords.sh  $mastername" 

sleep 59m

